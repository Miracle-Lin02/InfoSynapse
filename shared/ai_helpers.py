# -*- coding: utf-8 -*-
"""
AI helper functions for InfoSynapse application.
Contains render functions for AI-assisted features across different tabs.
"""

from typing import Dict, Any
import streamlit as st

from utils.recommend import AIAgent
from utils.prompts import (
    build_tab_helper_prompt,
    build_career_plan_prompt,
    build_mixed_plan_prompt,
    build_career_chat_prompt,
)

from shared.profiles import get_user_profile

# Import AI history module
try:
    from utils.ai_history import (
        save_conversation, 
        save_tab_helper_response,
        get_recent_conversation_history,
        get_tab_helper_history
    )
except ImportError:
    save_conversation = None
    save_tab_helper_response = None
    get_recent_conversation_history = None
    get_tab_helper_history = None

# Import personalized recommendation module
try:
    from utils.personalized_recommend import generate_personalized_prompt_context
except ImportError:
    generate_personalized_prompt_context = None


def _perform_rag_search(search_query: str, k: int = 5) -> str:
    """
    Perform explicit RAG search and return formatted context.
    
    Args:
        search_query: Keywords to search for in the knowledge base
        k: Number of documents to retrieve
        
    Returns:
        Formatted RAG context string, or empty string if search fails
    """
    try:
        from utils.rag_knowledge_base import get_rag_knowledge_base
        rag_kb = get_rag_knowledge_base()
        if rag_kb.available and search_query:
            rag_results = rag_kb.search(search_query, k=k)
            if rag_results:
                rag_context = "\n\n[çŸ¥è¯†åº“æ£€ç´¢ç»“æœ]\n"
                for i, result in enumerate(rag_results[:3], 1):
                    rag_context += f"{result['content']}\n---\n"
                return rag_context + "\n"
    except Exception:
        pass
    return ""


def format_review(r: Dict[str, Any]) -> str:
    """Format a review dictionary into a readable string."""
    reviewer = r.get("reviewer", "åŒ¿å")
    rating = r.get("rating", None)
    time_ = r.get("time", "")
    comment = r.get("comment", "")
    if rating is not None:
        header = f"{reviewer} â€” {rating}/5  Â·  {time_}"
    else:
        header = f"{reviewer}  Â·  {time_}"
    return f"**{header}**\n\n{comment}"


def _get_current_stage() -> str:
    """Get the current user's stage from their profile."""
    user = st.session_state.get("user")
    if not user:
        return ""
    profile = get_user_profile(user["username"])
    return profile.get("stage", "")


def safe_rerun():
    """Safely trigger a Streamlit rerun."""
    try:
        if hasattr(st, "rerun"):
            st.rerun()
            return
        if hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
            return
    except Exception:
        pass
    st.warning("è‡ªåŠ¨åˆ·æ–°ä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–°é¡µé¢ã€‚")


def render_tab_ai_helper(tab_key: str, title: str, ai_agent: AIAgent, context: str = ""):
    """Render a tab-specific AI helper widget."""
    st.markdown("---")
    st.subheader(f"ğŸ¤– æœ¬é¡µæ™ºèƒ½ä½“åŠ©æ‰‹ Â· {title}")
    stage = _get_current_stage() or "æœªè®¾ç½®"
    interests = ", ".join(st.session_state.get("user_interests", [])) or "æœªè®¾ç½®"

    role_hint_map = {
        "profile": "ä½ ä¸»è¦æ˜¯å¸®å­¦ç”Ÿæ¢³ç†ä¸ªäººæƒ…å†µã€ç›®æ ‡èŒä¸šå’Œé•¿æœŸè§„åˆ’ã€‚",
        "courses": "ä½ ä¸»è¦æ˜¯å¸®åŠ©å­¦ç”Ÿåœ¨å½“å‰ä¸“ä¸šå’Œé˜¶æ®µä¸‹ï¼Œåšé€‰è¯¾å†³ç­–å’Œå­¦ä¹ é¡ºåºè§„åˆ’ã€‚",
        "advisors": "ä½ ä¸»è¦æ˜¯å¸®åŠ©å­¦ç”Ÿé€‰æ‹©åˆé€‚çš„å¯¼å¸ˆï¼Œå¹¶ç»™å‡ºè”ç³»å¯¼å¸ˆçš„å»ºè®®ï¼ˆæ¯”å¦‚æ€ä¹ˆå†™ç¬¬ä¸€å°é‚®ä»¶ï¼‰ã€‚",
        "practice": "ä½ ä¸»è¦æ˜¯å¸®åŠ©å­¦ç”Ÿä»æ ¡å†…å®è·µèµ„æºä¸­é€‰å‡ºé€‚åˆå½“å‰é˜¶æ®µçš„æœºä¼šï¼Œä»¥åŠå¦‚ä½•å‚ä¸å’Œç§¯ç´¯æˆæœã€‚",
        "career_tab": "ä½ æ˜¯èŒä¸šè§„åˆ’é¡¾é—®ï¼Œè¡¥å……é¡µé¢å·²æœ‰æ¨èä¹‹å¤–çš„ä¸ªæ€§åŒ–å»ºè®®ã€‚",
        "github": "ä½ æ˜¯é¡¹ç›®é€‰é¢˜é¡¾é—®ï¼Œå¸®åŠ©å­¦ç”Ÿä»é¡¹ç›®ä¸­é€‰å‡ºæ›´é€‚åˆç»ƒæ‰‹å’Œç®€å†å±•ç¤ºçš„æ–¹å‘ã€‚",
        "community": "ä½ ä¸»è¦æ˜¯å¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ä½¿ç”¨ç¤¾åŒºï¼ˆæé—®ã€åˆ†äº«ã€è·Ÿè¿›è¯é¢˜ï¼‰ã€‚",
        "mixed": "ä½ ä¸»è¦æ˜¯å¸®åŠ©å­¦ç”ŸæŠŠç»¼åˆæ¨èè½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„å­¦ä¹ /å®è·µè·¯çº¿ã€‚",
        "admin": "ä½ ä¸»è¦æ˜¯å¸®åŠ©ç®¡ç†å‘˜æ€è€ƒå®¡æ ¸ç­–ç•¥å’Œå¦‚ä½•æ”¹è¿›ç³»ç»Ÿè§„åˆ™ã€‚",
    }
    role_hint = role_hint_map.get(tab_key, "ä½ æ˜¯ä¸€ä¸ªå¤§å­¦å­¦ä¸šä¸èŒä¸šè§„åˆ’åŠ©æ‰‹ã€‚")

    user_input = st.text_area(
        "å¯ä»¥è¡¥å……ä½ åœ¨æœ¬é¡µç›¸å…³çš„ç–‘é—®æˆ–æƒ³è®©æ™ºèƒ½ä½“å¸®ä½ æ€è€ƒçš„å†…å®¹ï¼ˆå¯é€‰ï¼‰ï¼š",
        height=80,
        key=f"tab_ai_input_{tab_key}",
    )

    if st.button("è®©æ™ºèƒ½ä½“æ ¹æ®æœ¬é¡µå†…å®¹ç»™ä¸€äº›å»ºè®®", key=f"tab_ai_btn_{tab_key}"):
        # Add personalized context if available
        personalized_context = ""
        conversation_history = ""
        rag_context = ""
        user = st.session_state.get("user")
        if user:
            username = user.get("username", "")
            if generate_personalized_prompt_context:
                personalized_context = generate_personalized_prompt_context(username)
            # Add conversation history for AI memory
            if get_recent_conversation_history:
                conversation_history = get_recent_conversation_history(username, limit=3)
        
        # Perform explicit RAG search with targeted keywords from user input and interests
        try:
            from utils.rag_knowledge_base import get_rag_knowledge_base
            rag_kb = get_rag_knowledge_base()
            if rag_kb.available:
                # Build search query from user input and interests
                search_terms = []
                if user_input:
                    search_terms.append(user_input)
                if interests and interests != "æœªè®¾ç½®":
                    search_terms.append(interests)
                
                search_query = " ".join(search_terms) if search_terms else context
                if search_query:
                    rag_results = rag_kb.search(search_query, k=5)
                    if rag_results:
                        rag_context = "\n\n[çŸ¥è¯†åº“æ£€ç´¢ç»“æœ]\n"
                        for i, result in enumerate(rag_results[:3], 1):
                            rag_context += f"{result['content']}\n---\n"
                        rag_context += "\n"
        except Exception as e:
            # RAG search failed, continue without it
            pass
        
        # Combine all context: history + personalized + page context + RAG results
        full_context = ""
        if conversation_history:
            full_context += conversation_history + "\n"
        if personalized_context:
            full_context += personalized_context + "\n"
        if rag_context:
            full_context += rag_context + "\n"
        if context:
            full_context += context
        
        prompt = build_tab_helper_prompt(
            tab_key=tab_key,
            role_hint=role_hint,
            title=title,
            stage=stage,
            interests=interests,
            context=full_context,
            user_input=user_input or "",
        )
        with st.spinner("æ™ºèƒ½ä½“æ­£åœ¨æ€è€ƒè¿™é¡µå¯ä»¥æ€ä¹ˆç”¨å¾—æ›´å¥½..."):
            # Check if agent supports use_rag parameter (LangChainAgent)
            # Note: use_rag=False since we already added RAG context manually above
            try:
                ans = ai_agent.call(prompt, temperature=0.5, max_tokens=1200, use_rag=False)
            except TypeError:
                # Fallback for simple AIAgent that doesn't support use_rag
                ans = ai_agent.call(prompt, temperature=0.5, max_tokens=1200)
        if "ã€æœ¬åœ°å›é€€ã€‘" in ans:
            st.warning("å½“å‰æ™ºèƒ½ä½“æœåŠ¡æš‚ä¸å¯ç”¨ï¼Œä¸‹é¢æ˜¯æœ¬åœ°ç¤ºä¾‹å›ç­”ï¼Œä»…ä¾›å‚è€ƒã€‚")
        st.session_state["tab_ai_answers"][tab_key] = ans
        
        # Save to AI history
        if save_tab_helper_response and user:
            save_tab_helper_response(
                username=user.get("username", ""),
                tab_key=tab_key,
                question=user_input or f"è¯·ç»™å‡ºå…³äº{title}çš„å»ºè®®",
                answer=ans
            )

    if st.session_state["tab_ai_answers"].get(tab_key):
        st.markdown("#### æœ¬é¡µæ™ºèƒ½ä½“å»ºè®®")
        st.markdown(st.session_state["tab_ai_answers"][tab_key])


def render_career_ai_summary(ai_agent: AIAgent):
    """Render AI-generated career planning summary."""
    interests = st.session_state.get("user_interests", [])
    location = st.session_state.get("work_location", "å…¨å›½")
    careers = st.session_state.get("career_recommendations", [])
    stage = _get_current_stage() or "æœªè®¾ç½®"

    st.markdown("---")
    st.subheader("ğŸ¤– æ™ºèƒ½åŠ©æ‰‹ Â· æ±‚èŒè¡ŒåŠ¨è®¡åˆ’")

    if not careers:
        st.info("å…ˆç‚¹å‡»ä¸Šé¢çš„ã€æ™ºèƒ½æ¨èèŒä¸š & å­¦ä¹ è·¯å¾„ã€ç”ŸæˆèŒä¸šåˆ—è¡¨ï¼Œå†ä½¿ç”¨æ™ºèƒ½åŠ©æ‰‹ã€‚")
        return

    user_extra = st.text_area(
        "å¯ä»¥è¡¥å……ä¸€äº›ä½ çš„æƒ…å†µï¼ˆå¯é€‰ï¼‰ï¼Œæ¯”å¦‚æ˜¯å¦è€ƒç ”ã€å·²æœ‰é¡¹ç›®ç»å†ç­‰ï¼š",
        height=80,
        key="career_ai_extra",
    )

    if st.button("è®©æ™ºèƒ½ä½“æ€»ç»“ä¸€ä»½èŒä¸šè¡ŒåŠ¨è®¡åˆ’", key="career_ai_btn"):
        # Perform explicit RAG search with interests and user input
        search_terms = []
        if interests:
            search_terms.extend(interests)
        if user_extra:
            search_terms.append(user_extra)
        if careers:
            # Add some career keywords
            career_keywords = [c.get('career', '') for c in careers[:3]]
            search_terms.extend(career_keywords)
        
        search_query = " ".join(search_terms)
        rag_context = _perform_rag_search(search_query, k=5)
        
        career_brief = "\n".join(
            [
                f"- {c.get('career')}ï¼ˆæŠ€èƒ½ï¼š{', '.join(c.get('skills', []))}ï¼›è–ªèµ„ï¼š{c.get('salary','')}ï¼›å…¬å¸ï¼š{c.get('companies','')}ï¼‰"
                for c in careers[:6]
            ]
        )
        
        # Add RAG context to the career brief
        if rag_context:
            career_brief = rag_context + "\n" + career_brief
        
        prompt = build_career_plan_prompt(
            careers_brief=career_brief,
            interests=", ".join(interests),
            location=location,
            stage=stage,
            extra=user_extra or "",
        )
        with st.spinner("æ™ºèƒ½ä½“æ­£åœ¨ç»¼åˆåˆ†æä½ çš„èŒä¸šè§„åˆ’..."):
            try:
                summary = ai_agent.call(prompt, temperature=0.4, max_tokens=2000, use_rag=False)
            except TypeError:
                summary = ai_agent.call(prompt, temperature=0.4, max_tokens=2000)
        if "ã€æœ¬åœ°å›é€€ã€‘" in summary:
            st.warning("å½“å‰æœªé…ç½® DEEPSEEK_API_KEY æˆ–æœåŠ¡ä¸å¯ç”¨ï¼ŒèŒä¸šè®¡åˆ’ä¸ºæœ¬åœ°ç¤ºä¾‹ï¼Œä»…ä¾›å‚è€ƒã€‚")
        st.session_state["career_ai_summary"] = summary

    if st.session_state.get("career_ai_summary"):
        st.markdown("#### æ™ºèƒ½åŠ©æ‰‹å»ºè®®")
        st.markdown(st.session_state["career_ai_summary"])
        md_content = st.session_state["career_ai_summary"]
        st.download_button(
            "ä¸‹è½½èŒä¸šè¡ŒåŠ¨è®¡åˆ’ï¼ˆMarkdownï¼‰",
            data=md_content.encode("utf-8"),
            file_name="career_plan.md",
            mime="text/markdown",
            key="download_career_plan",
        )


def render_career_chat(ai_agent: AIAgent):
    """Render multi-turn career chat assistant."""
    st.markdown("---")
    st.subheader("ğŸ—£ èŒä¸šå¯¹è¯åŠ©æ‰‹ï¼ˆå¤šè½®ï¼‰")

    careers = st.session_state.get("career_recommendations", [])
    if not careers:
        st.info("å…ˆä½¿ç”¨ä¸Šé¢çš„ã€æ™ºèƒ½æ¨èèŒä¸š & å­¦ä¹ è·¯å¾„ã€ç”ŸæˆèŒä¸šåˆ—è¡¨ï¼Œå†æ¥å’ŒèŒä¸šåŠ©æ‰‹å¯¹è¯ã€‚")
        return

    chat = st.session_state.get("career_chat", [])

    if chat:
        for msg in chat:
            if msg["role"] == "user":
                st.markdown(f"**ä½ ï¼š** {msg['content']}")
            else:
                st.markdown(f"**èŒä¸šåŠ©æ‰‹ï¼š** {msg['content']}")
    else:
        st.caption("è¿™é‡Œæ˜¯ä¸€ä¸ªå¯ä»¥æŒç»­è¿½é—®çš„èŒä¸šåŠ©æ‰‹ï¼Œä½ å¯ä»¥å¤šè½®è¡¥å……è‡ªå·±çš„æƒ…å†µå’Œç–‘é—®ã€‚")

    user_msg = st.text_area("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç»§ç»­å’ŒèŒä¸šåŠ©æ‰‹èŠï¼š", key="career_chat_input")

    col_send, col_clear = st.columns([1, 1])
    with col_send:
        send_clicked = st.button("å‘é€", key="career_chat_send")
    with col_clear:
        clear_clicked = st.button("æ¸…ç©ºå¯¹è¯", key="career_chat_clear")

    if clear_clicked:
        st.session_state["career_chat"] = []
        safe_rerun()
        return

    if not send_clicked:
        return

    if not user_msg.strip():
        st.warning("é—®é¢˜ä¸èƒ½ä¸ºç©º")
        return

    chat.append({"role": "user", "content": user_msg.strip()})

    interests_str = ", ".join(st.session_state.get("user_interests", [])) or "æœªè®¾ç½®"
    location = st.session_state.get("work_location", "å…¨å›½")
    stage = _get_current_stage() or "æœªè®¾ç½®"

    # Perform explicit RAG search with user's current message and interests
    search_terms = [user_msg.strip()]
    if st.session_state.get("user_interests"):
        search_terms.extend(st.session_state.get("user_interests"))
    search_query = " ".join(search_terms)
    rag_context = _perform_rag_search(search_query, k=5)

    careers_brief = "\n".join(
        [
            f"- {c.get('career')}ï¼ˆæŠ€èƒ½ï¼š{', '.join(c.get('skills', []))}ï¼›è–ªèµ„ï¼š{c.get('salary','')}ï¼‰"
            for c in careers[:5]
        ]
    )
    
    # Add RAG context to careers brief
    if rag_context:
        careers_brief = rag_context + "\n" + careers_brief

    history_lines = []
    for m in chat:
        if m["role"] == "user":
            history_lines.append(f"å­¦ç”Ÿï¼š{m['content']}")
        else:
            history_lines.append(f"èŒä¸šåŠ©æ‰‹ï¼š{m['content']}")
    history_text = "\n".join(history_lines)

    prompt = build_career_chat_prompt(
        careers_brief=careers_brief,
        interests=interests_str,
        location=location,
        stage=stage,
        history_text=history_text,
    )

    with st.spinner("èŒä¸šåŠ©æ‰‹æ­£åœ¨æ€è€ƒ..."):
        try:
            ans = ai_agent.call(prompt, temperature=0.5, max_tokens=1500, use_rag=False)
        except TypeError:
            ans = ai_agent.call(prompt, temperature=0.5, max_tokens=1500)

    if "ã€æœ¬åœ°å›é€€ã€‘" in ans:
        st.warning("å½“å‰æ™ºèƒ½ä½“æœåŠ¡æš‚ä¸å¯ç”¨ï¼Œä¸‹é¢æ˜¯æœ¬åœ°ç¤ºä¾‹å›ç­”ï¼Œä»…ä¾›å‚è€ƒã€‚")

    chat.append({"role": "assistant", "content": ans})
    st.session_state["career_chat"] = chat
    
    # Save career chat to history
    user = st.session_state.get("user")
    if save_conversation and user and len(chat) >= 2:
        # Only save periodically (every 4 messages or when clearing)
        if len(chat) % 4 == 0 or len(chat) == 2:
            save_conversation(
                username=user.get("username", ""),
                conversation_type="career_chat",
                title="èŒä¸šè§„åˆ’å’¨è¯¢",
                messages=chat,
                context={
                    "interests": interests_str,
                    "location": location,
                    "stage": stage,
                    "careers": [c.get("career", "") for c in careers[:5]]
                }
            )
    
    safe_rerun()


def render_mixed_ai_plan(ai_agent: AIAgent):
    """Render AI-generated mixed recommendations action plan."""
    interests = st.session_state.get("user_interests", [])
    combined = st.session_state.get("combined_recs", [])
    stage = _get_current_stage() or "æœªè®¾ç½®"

    st.markdown("---")
    st.subheader("ğŸ¤– æ™ºèƒ½åŠ©æ‰‹ Â· ç»¼åˆè¡ŒåŠ¨è·¯çº¿")

    if not combined:
        st.info("å…ˆç‚¹å‡»ä¸Šé¢çš„ã€ç”Ÿæˆç»¼åˆæ¨èã€ï¼Œå†ä½¿ç”¨æ™ºèƒ½åŠ©æ‰‹ã€‚")
        return

    force_refresh = st.checkbox("å¼ºåˆ¶é‡æ–°ç”Ÿæˆç»¼åˆè¡ŒåŠ¨è®¡åˆ’", key="mix_force_refresh")

    user_extra = st.text_area(
        "ç®€å•è¯´ä¸€ä¸‹ä½ ç›®å‰çš„æ—¶é—´ç²¾åŠ›å’Œç›®æ ‡ï¼ˆå¯é€‰ï¼‰ï¼Œä¾‹å¦‚ï¼šæ¯å‘¨èƒ½æŠ•å…¥å¤šä¹…ã€çŸ­æœŸç›®æ ‡æ˜¯å•¥ï¼š",
        height=80,
        key="mix_ai_extra",
    )

    if st.button("è®©æ™ºèƒ½ä½“åŸºäºè¿™äº›æ¨èåˆ¶å®šè¡ŒåŠ¨è®¡åˆ’", key="mix_ai_btn2"):
        if st.session_state.get("mix_ai_plan") and not force_refresh:
            st.info(
                "å·²å­˜åœ¨ä¸Šä¸€è½®ç»¼åˆè¡ŒåŠ¨è®¡åˆ’ï¼Œå‘ä¸‹æ»šåŠ¨å³å¯æŸ¥çœ‹ã€‚å¦‚éœ€é‡æ–°ç”Ÿæˆï¼Œè¯·å‹¾é€‰ã€å¼ºåˆ¶é‡æ–°ç”Ÿæˆç»¼åˆè¡ŒåŠ¨è®¡åˆ’ã€ã€‚"
            )
        else:
            # Perform explicit RAG search with interests and user input
            search_terms = []
            if interests:
                search_terms.extend(interests)
            if user_extra:
                search_terms.append(user_extra)
            # Add some item names from recommendations
            if combined:
                item_names = [item.get('name', '') for item in combined[:5]]
                search_terms.extend(item_names)
            
            search_query = " ".join(search_terms)
            rag_context = _perform_rag_search(search_query, k=5)
            
            brief = "\n".join(
                [
                    f"- [{item.get('type')}] {item.get('name')}ï¼ˆæ¥æºï¼š{item.get('source')}ï¼Œå¾—åˆ†ï¼š{item.get('score')}ï¼›åŒ¹é…åŸå› ï¼š{item.get('match_reason')}ï¼‰"
                    for item in combined[:15]
                ]
            )
            
            # Add RAG context to brief
            if rag_context:
                brief = rag_context + "\n" + brief
            
            prompt = build_mixed_plan_prompt(
                brief_recs=brief,
                interests=", ".join(interests),
                stage=stage,
                extra=user_extra or "",
            )
            with st.spinner("æ™ºèƒ½ä½“æ­£åœ¨åˆ¶å®šç»¼åˆè¡ŒåŠ¨è®¡åˆ’..."):
                try:
                    plan = ai_agent.call(prompt, temperature=0.4, max_tokens=2200, use_rag=False)
                except TypeError:
                    plan = ai_agent.call(prompt, temperature=0.4, max_tokens=2200)
            if "ã€æœ¬åœ°å›é€€ã€‘" in plan:
                st.warning("å½“å‰æœªé…ç½® DEEPSEEK_API_KEY æˆ–æœåŠ¡ä¸å¯ç”¨ï¼Œç»¼åˆè¡ŒåŠ¨è®¡åˆ’ä¸ºæœ¬åœ°ç¤ºä¾‹ï¼Œä»…ä¾›å‚è€ƒã€‚")
            st.session_state["mix_ai_plan"] = plan

    if st.session_state.get("mix_ai_plan"):
        st.markdown("#### æ™ºèƒ½åŠ©æ‰‹ç»™å‡ºçš„è¡ŒåŠ¨è·¯çº¿")
        st.markdown(st.session_state["mix_ai_plan"])
        md_content = st.session_state["mix_ai_plan"]
        st.download_button(
            "ä¸‹è½½ç»¼åˆè¡ŒåŠ¨è®¡åˆ’ï¼ˆMarkdownï¼‰",
            data=md_content.encode("utf-8"),
            file_name="mixed_plan.md",
            mime="text/markdown",
            key="download_mixed_plan",
        )
