# -*- coding: utf-8 -*-
"""
æ¨èé€»è¾‘æ¨¡å—ï¼š
- AIAgent åŒ…è£…
- KB + GitHub ç»¼åˆæ¨è
- éšæœº GitHub é¡¹ç›®æ¨èï¼ˆè°ƒç”¨ github_crawler + ç¼“å­˜ï¼‰
- æŒ‰å…´è¶£+åœ°åŒºçš„èŒä¸šæ¨è & å­¦ä¹ è·¯å¾„ï¼ˆå·²æ”¾å®½æ¡ä»¶ï¼Œå•ä¸ªå…´è¶£ä¹Ÿèƒ½è¿”å›èŒä¸šï¼‰
- æ™ºèƒ½ä½“æ¨èé¡¹ç›®ï¼ˆåŸºäºå…´è¶£ & æŠ€èƒ½ & ç›®æ ‡èŒä¸šï¼‰
"""

import json
import math
import random
import logging
from typing import List, Dict, Any

import requests
import streamlit as st

logger = logging.getLogger("recommend")


class AIAgent:
    def __init__(
        self,
        api_key: str = "",
        api_url: str = "https://api.deepseek.com/chat/completions",
        timeout: int = 120,
    ):
        self.api_key = api_key
        self.api_url = api_url
        self.timeout = timeout

    def _local_template(self, prompt: str) -> str:
        if "æ¨è" in prompt and "é¡¹ç›®" in prompt:
            return """```json
[
  {
    "name": "Vue 3",
    "url": "https://github.com/vuejs/core",
    "description": "æ˜“å­¦æ˜“ç”¨çš„æ¸è¿›å¼ JavaScript æ¡†æ¶",
    "learning_value": "å­¦ä¹ ç°ä»£å‰ç«¯æ¶æ„ä¸å“åº”å¼åŸç†",
    "difficulty": "medium",
    "estimated_time": "8",
    "tech_stack": ["TypeScript", "Vue"]
  },
  {
    "name": "FastAPI",
    "url": "https://github.com/tiangolo/fastapi",
    "description": "ç°ä»£ã€é«˜æ€§èƒ½ Python Web æ¡†æ¶",
    "learning_value": "æŒæ¡å¼‚æ­¥ç¼–ç¨‹ä¸ API è®¾è®¡",
    "difficulty": "medium",
    "estimated_time": "6",
    "tech_stack": ["Python", "ASGI"]
  }
]
```"""
        if "èŒä¸š" in prompt or "career" in prompt:
            return "ã€æœ¬åœ°å›é€€ã€‘æ ¹æ®ä½ çš„å…´è¶£ï¼Œæ¨èä»¥ä¸‹èŒä¸šæ–¹å‘ï¼š\n- å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ\n- æ•°æ®åˆ†æå¸ˆ\n- AIå·¥ç¨‹å¸ˆ"
        if "å­¦ä¹ è·¯å¾„" in prompt or "learning path" in prompt:
            return "ã€æœ¬åœ°å›é€€ã€‘å»ºè®®ï¼šåŸºç¡€-è¿›é˜¶-é¡¹ç›®ä¸‰é˜¶æ®µï¼Œæ¯é˜¶æ®µ 1-2 ä¸ªæœˆï¼Œé…åˆ 2-3 ä¸ªå°é¡¹ç›®ã€‚"
        return "ã€æœ¬åœ°å›é€€ã€‘è¯·é…ç½® DEEPSEEK_API_KEY ä»¥ä½¿ç”¨çœŸå® AIã€‚"

    def call(self, prompt: str, temperature: float = 0.7, max_tokens: int = 800) -> str:
        if not self.api_key:
            return self._local_template(prompt)
        try:
            payload = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens,
            }
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            }
            r = requests.post(
                self.api_url, json=payload, headers=headers, timeout=self.timeout
            )
            r.raise_for_status()
            d = r.json()
            return (
                d.get("choices", [{}])[0]
                .get("message", {})
                .get("content", "")
                or d.get("choices", [{}])[0].get("text", "")
                or self._local_template(prompt)
            )
        except Exception as e:
            logger.warning(f"AIAgent.call failed: {e}")
            return self._local_template(prompt)


# Configuration constants
NATIONAL_STRATEGIC_BONUS = 2.0  # Bonus score for national strategic positions
LOCATION_GLOBAL = "å…¨å›½"  # Global location marker

# Social value and patriotic keywords for filtering
SOCIAL_VALUE_KEYWORDS = [
    "æŒ‘æˆ˜æ¯", "çº¢è‰²", "å…¬ç›Š", "åŠ©è€", "ä¹¡æ‘", "æŒ¯å…´",
    "å¿—æ„¿", "æ‰¶è´«", "ç¤¾ä¼šæœåŠ¡", "å¼€æº", "å›½äº§"
]

PATRIOTIC_OPENSOURCE_KEYWORDS = [
    "openeuler", "openkylin", "opengauss", "mindspore", "paddlepaddle",
    "china", "chinese", "å›½äº§", "è‡ªä¸»", "å¼€æº", "å…¬ç›Š", "education",
    "healthcare", "environmental", "accessibility", "charity"
]

DEFAULT_WEIGHTS = {
    "INTEREST_NAME_WEIGHT": 30.0,
    "INTEREST_DESC_WEIGHT": 18.0,
    "TAG_MATCH_WEIGHT": 12.0,
    "KB_BASE_SCORE": 6.0,
    "SOURCE_GITHUB_BONUS": 5.0,
    "SOURCE_KB_BONUS": 2.0,
    "GITHUB_STAR_WEIGHT_FACTOR": 6.0,
    "GITHUB_STAR_MAX_BONUS": 40.0,
    "RANDOM_TIE_BREAKER": 1.5,
}

CONFIG = {
    "RECOMMEND_MAX_ITEMS": 12,
    "GITHUB_FETCH_PER_TOPIC": 30,
    "GITHUB_PICK_TOTAL": 8,
}
CONFIG.update(DEFAULT_WEIGHTS)


INTEREST_TOPIC_MAP: Dict[str, List[str]] = {
    "Pythonå¼€å‘": ["python", "django", "fastapi", "flask"],
    "æœºå™¨å­¦ä¹ ": ["machine-learning", "pytorch", "tensorflow", "scikit-learn"],
    "å‰ç«¯": ["javascript", "react", "vue", "frontend", "typescript"],
    "åç«¯": ["backend", "spring-boot", "go", "nodejs", "microservices"],
    "ç®—æ³•": ["algorithm", "data-structures", "leetcode", "competitive-programming"],
    "åµŒå…¥å¼": ["embedded-systems", "stm32", "arduino", "rtos"],
    "åŒºå—é“¾": ["blockchain", "solidity", "web3", "ethereum"],
    "è®¡ç®—æœºè§†è§‰": ["computer-vision", "opencv", "image-processing", "yolo"],
}


def _kb_items_as_candidates(kb: Dict[str, Any]) -> List[Dict[str, Any]]:
    candidates = []
    for major, course_list in kb.get("courses", {}).items():
        for c in course_list:
            candidates.append(
                {
                    "id": f"course:{c.get('code','')}",
                    "name": c.get("name"),
                    "type": "course",
                    "desc": c.get("outline", ""),
                    "tags": [c.get("level", ""), major],
                    "source": "KB",
                    "url": c.get("link", ""),
                    "meta": c,
                }
            )
    for p in kb.get("practice", []):
        candidates.append(
            {
                "id": f"practice:{p.get('name')}",
                "name": p.get("name"),
                "type": "practice",
                "desc": p.get("desc", ""),
                "tags": [p.get("type", "")],
                "source": "KB",
                "url": p.get("link", ""),
                "meta": p,
            }
        )
    for j in kb.get("jds", []):
        candidates.append(
            {
                "id": f"jd:{j.get('company')}_{j.get('position')}",
                "name": f"{j.get('company')} - {j.get('position')}",
                "type": "job",
                "desc": j.get("jd", ""),
                "tags": j.get("skills", []),
                "source": "KB",
                "url": j.get("link", ""),
                "meta": j,
            }
        )
    for a in kb.get("advisors", []):
        tags = []
        if a.get("department"):
            tags.append(a.get("department"))
        if a.get("research"):
            tags += [x.strip() for x in a.get("research", "").split("/") if x.strip()]
        candidates.append(
            {
                "id": f"advisor:{a.get('name')}",
                "name": a.get("name"),
                "type": "advisor",
                "desc": a.get("research", ""),
                "tags": tags,
                "source": "KB",
                "url": a.get("homepage", ""),
                "meta": a,
            }
        )
    return candidates


def _github_repos_candidates_from_session(interests: List[str]) -> List[Dict[str, Any]]:
    out = []
    cached = st.session_state.get("github_repos", [])
    if cached:
        for r in cached:
            key = r.get("full_name") or f"{r.get('owner','')}/{r.get('name','')}"
            out.append(
                {
                    "id": f"github:{key}",
                    "name": key,
                    "type": "github",
                    "desc": r.get("description", ""),
                    "tags": [r.get("language", "")] + (
                        [r.get("matched_interest")] if r.get("matched_interest") else []
                    ),
                    "source": "GitHub",
                    "url": r.get("html_url"),
                    "stars": r.get("stargazers_count", r.get("stargazers", 0)),
                    "meta": r,
                }
            )
    return out


def _score_candidate_live(candidate: Dict[str, Any], interests: List[str]) -> float:
    weights = {
        k: float(st.session_state.get(k, CONFIG.get(k, 0.0)))
        for k in DEFAULT_WEIGHTS.keys()
    }
    score = 0.0
    name = (candidate.get("name") or "").lower()
    desc = (candidate.get("desc") or "").lower()
    tags = [str(t).lower() for t in candidate.get("tags", []) if t]
    for i in interests:
        ik = i.lower()
        if ik in name:
            score += weights["INTEREST_NAME_WEIGHT"]
        if ik in desc:
            score += weights["INTEREST_DESC_WEIGHT"]
        if any(ik in t for t in tags):
            score += weights["TAG_MATCH_WEIGHT"]
    if candidate.get("source") == "GitHub":
        stars = candidate.get("stars", 0) or 0
        star_bonus = math.log1p(stars) * weights["GITHUB_STAR_WEIGHT_FACTOR"]
        star_bonus = min(star_bonus, weights["GITHUB_STAR_MAX_BONUS"])
        score += star_bonus + weights["SOURCE_GITHUB_BONUS"]
    else:
        score += weights["KB_BASE_SCORE"] + weights["SOURCE_KB_BONUS"]
        meta = candidate.get("meta", {})
        heat = meta.get("çƒ­åº¦") if isinstance(meta.get("çƒ­åº¦"), (int, float)) else 0
        if heat:
            score += min(8.0, heat / 10.0)
    score += random.uniform(0, weights["RANDOM_TIE_BREAKER"])
    return score


def get_combined_recommendations(
    kb: Dict[str, Any], interests: List[str], max_items: int = 12
) -> List[Dict[str, Any]]:
    if not interests:
        return []
    kb_cands = _kb_items_as_candidates(kb)
    gh_cands = _github_repos_candidates_from_session(interests)
    all_cands = kb_cands + gh_cands
    scored = []
    for c in all_cands:
        s = _score_candidate_live(c, interests)
        cc = dict(c)
        cc["score"] = round(s, 2)
        reason_parts = []
        for i in interests:
            ik = i.lower()
            if ik in (c.get("name", "") or "").lower():
                reason_parts.append(f"åç§°åŒ¹é…ï¼š{i}")
            if ik in (c.get("desc", "") or "").lower():
                reason_parts.append(f"æè¿°åŒ¹é…ï¼š{i}")
            if any(ik in str(t).lower() for t in c.get("tags", [])):
                reason_parts.append(f"æ ‡ç­¾åŒ¹é…ï¼š{i}")
        cc["match_reason"] = "; ".join(reason_parts) or "å…³é”®è¯åŒ¹é…è¾ƒä½"
        scored.append(cc)
    scored.sort(key=lambda x: x.get("score", 0), reverse=True)
    return scored[:max_items]


def weighted_sample_without_replacement(
    items: List[Dict[str, Any]], weights: List[float], k: int
) -> List[Dict[str, Any]]:
    if not items or k <= 0:
        return []
    if len(items) <= k:
        return items.copy()
    pool = items.copy()
    w = weights.copy()
    selected = []
    for _ in range(min(k, len(pool))):
        total = sum(w)
        if total <= 0:
            random.shuffle(pool)
            selected.extend(pool[: (k - len(selected))])
            break
        r = random.random() * total
        cum = 0.0
        idx = None
        for i, weight in enumerate(w):
            cum += weight
            if r <= cum:
                idx = i
                break
        if idx is None:
            idx = len(w) - 1
        selected.append(pool[idx])
        pool.pop(idx)
        w.pop(idx)
    return selected


def recommend_random_repos(
    interests: List[str],
    github_crawler=None,
    per_topic_fetch: int = None,
    total_pick: int = None,
) -> List[Dict[str, Any]]:
    per_topic_fetch = per_topic_fetch or CONFIG["GITHUB_FETCH_PER_TOPIC"]
    total_pick = total_pick or CONFIG["GITHUB_PICK_TOTAL"]
    if not interests:
        return []

    candidates = []
    seen = set()
    topics_used: List[str] = []

    if github_crawler:
        topic_list: List[str] = []
        for interest in interests:
            mapped = INTEREST_TOPIC_MAP.get(interest, [])
            if mapped:
                topic_list.extend(mapped)
            else:
                topic_list.append(interest)
        topic_list = list(dict.fromkeys([t for t in topic_list if t]))
        topics_used = topic_list.copy()

        for topic in topic_list:
            try:
                fetched = github_crawler.top_repos_for_topic(
                    topic, top_n=per_topic_fetch
                )
            except Exception as e:
                logger.warning(f"GitHub fetch error for topic={topic}: {e}")
                fetched = []
            for r in fetched:
                key = r.get("full_name") or f"{r.get('owner','')}/{r.get('name','')}"
                if not key or key in seen:
                    continue
                seen.add(key)
                item = {
                    "full_name": key,
                    "html_url": r.get("html_url") or f"https://github.com/{key}",
                    "description": r.get("description") or "",
                    "stargazers_count": int(
                        r.get("stargazers_count", r.get("stargazers", 0) or 0)
                    ),
                    "language": r.get("language") or "",
                    "matched_interest": topic,
                }
                candidates.append(item)

        if candidates:
            st.session_state["github_repos"] = candidates

    if not candidates and st.session_state.get("github_repos"):
        for r in st.session_state["github_repos"]:
            key = r.get("full_name") or r.get("name")
            if not key or key in seen:
                continue
            seen.add(key)
            candidates.append(
                {
                    "full_name": key,
                    "html_url": r.get("html_url") or f"https://github.com/{key}",
                    "description": r.get("description") or "",
                    "stargazers_count": int(
                        r.get("stargazers_count", r.get("stargazers", 0) or 0)
                    ),
                    "language": r.get("language") or "",
                    "matched_interest": r.get("matched_interest", ""),
                }
            )

    st.session_state["github_topics_used"] = topics_used
    st.session_state["github_fetch_count"] = len(candidates)

    if not candidates:
        return []

    weights = [
        math.log1p(c.get("stargazers_count", 0) or 0) + 0.1 for c in candidates
    ]
    k = min(total_pick, len(candidates))
    selected = weighted_sample_without_replacement(candidates, weights, k)
    random.shuffle(selected)
    return selected


# ===== èŒä¸šé…ç½®ï¼ˆç”¨äºèŒä¸šæ¨èï¼Œæ”¾å®½åŒ¹é…æ¡ä»¶ï¼‰ =====

CAREER_CONFIG: List[Dict[str, Any]] = [
    {
        "career": "åç«¯å·¥ç¨‹å¸ˆ",
        "tags": ["Pythonå¼€å‘", "åç«¯", "Webå¼€å‘"],
        "locations": [],  # ç©ºåˆ—è¡¨è¡¨ç¤ºåœ°åŒºä¸é™
        "skills": ["Python/Java", "æ•°æ®åº“", "Linux", "API è®¾è®¡"],
        "salary": "12k-25k/æœˆ",
        "companies": "äº’è”ç½‘å¤§å‚ã€ä¸­å°å‹äº’è”ç½‘å…¬å¸",
        "national_strategic": False,
    },
    {
        "career": "æ•°æ®åˆ†æå¸ˆ",
        "tags": ["æ•°æ®åˆ†æ", "Pythonå¼€å‘", "æœºå™¨å­¦ä¹ "],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "å¹¿å·", "æ­å·"],
        "skills": ["SQL", "Python", "Excel", "å¯è§†åŒ–"],
        "salary": "12k-22k/æœˆ",
        "companies": "äº’è”ç½‘ã€æ¶ˆè´¹ã€é‡‘èã€å’¨è¯¢",
        "national_strategic": False,
    },
    {
        "career": "æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ",
        "tags": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç®—æ³•", "Pythonå¼€å‘"],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "å¹¿å·"],
        "skills": ["Python", "PyTorch", "TensorFlow", "Linux"],
        "salary": "20k-35k/æœˆ",
        "companies": "äº’è”ç½‘å¤§å‚ã€AI å…¬å¸ã€ç‹¬è§’å…½",
        "national_strategic": False,
    },
    {
        "career": "ç®—æ³•å·¥ç¨‹å¸ˆ",
        "tags": ["æœºå™¨å­¦ä¹ ", "ç®—æ³•", "æ•°æ®æŒ–æ˜"],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "å—äº¬", "æˆéƒ½"],
        "skills": ["Python", "C++", "æ•°æ®ç»“æ„ä¸ç®—æ³•", "çº¿æ€§ä»£æ•°"],
        "salary": "18k-30k/æœˆ",
        "companies": "äº’è”ç½‘å¤§å‚ã€å¹¿å‘Šå¹³å°ã€é‡‘èç§‘æŠ€",
        "national_strategic": False,
    },
    {
        "career": "å‰ç«¯å·¥ç¨‹å¸ˆ",
        "tags": ["å‰ç«¯", "Webå¼€å‘"],
        "locations": [],
        "skills": ["JavaScript/TypeScript", "HTML/CSS", "å‰ç«¯æ¡†æ¶"],
        "salary": "10k-22k/æœˆ",
        "companies": "å¤§éƒ¨åˆ†äº’è”ç½‘å…¬å¸",
        "national_strategic": False,
    },
    # å›½å®¶æˆ˜ç•¥é‡ç‚¹é¢†åŸŸå²—ä½
    {
        "career": "èŠ¯ç‰‡è®¾è®¡å·¥ç¨‹å¸ˆï¼ˆå›½å®¶æˆ˜ç•¥ï¼‰",
        "tags": ["åµŒå…¥å¼", "ç®—æ³•", "ç¡¬ä»¶"],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æˆéƒ½", "è¥¿å®‰", "æ­å·"],
        "skills": ["æ•°å­—ç”µè·¯", "Verilog/VHDL", "èŠ¯ç‰‡æ¶æ„", "EDA å·¥å…·"],
        "salary": "20k-40k/æœˆ",
        "companies": "åä¸ºæµ·æ€ã€ä¸­èŠ¯å›½é™…ã€ç´«å…‰å±•é”ã€é¾™èŠ¯ä¸­ç§‘",
        "national_strategic": True,
        "strategic_field": "èŠ¯ç‰‡è‡ªä¸»",
    },
    {
        "career": "ç½‘ç»œå®‰å…¨å·¥ç¨‹å¸ˆï¼ˆå›½å®¶æˆ˜ç•¥ï¼‰",
        "tags": ["ç½‘ç»œå®‰å…¨", "åç«¯", "ç®—æ³•"],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·", "æˆéƒ½"],
        "skills": ["æ¸—é€æµ‹è¯•", "å¯†ç å­¦", "å®‰å…¨åè®®", "Python/C++"],
        "salary": "18k-35k/æœˆ",
        "companies": "360ã€ç»¿ç›Ÿç§‘æŠ€ã€å¯æ˜æ˜Ÿè¾°ã€å¥‡å®‰ä¿¡",
        "national_strategic": True,
        "strategic_field": "ç½‘ç»œå®‰å…¨",
    },
    {
        "career": "èˆªå¤©è½¯ä»¶å·¥ç¨‹å¸ˆï¼ˆå›½å®¶æˆ˜ç•¥ï¼‰",
        "tags": ["åµŒå…¥å¼", "ç®—æ³•", "åç«¯"],
        "locations": ["åŒ—äº¬", "è¥¿å®‰", "ä¸Šæµ·", "æˆéƒ½"],
        "skills": ["C/C++", "å®æ—¶æ“ä½œç³»ç»Ÿ", "å«æ˜Ÿé€šä¿¡", "è½¯ä»¶æµ‹è¯•"],
        "salary": "15k-30k/æœˆ",
        "companies": "ä¸­å›½èˆªå¤©ç§‘æŠ€é›†å›¢ã€ä¸­å›½èˆªå¤©ç§‘å·¥é›†å›¢ã€èˆªå¤©ç§‘æŠ€æ§è‚¡",
        "national_strategic": True,
        "strategic_field": "èˆªå¤©ç§‘æŠ€",
    },
    {
        "career": "æ™ºæ…§ç”µç½‘å·¥ç¨‹å¸ˆï¼ˆå›½å®¶æˆ˜ç•¥ï¼‰",
        "tags": ["åµŒå…¥å¼", "åç«¯", "ç‰©è”ç½‘"],
        "locations": ["åŒ—äº¬", "ä¸Šæµ·", "å—äº¬", "æ­¦æ±‰", "æˆéƒ½"],
        "skills": ["ç”µåŠ›ç³»ç»Ÿ", "ç‰©è”ç½‘", "å¤§æ•°æ®åˆ†æ", "Python"],
        "salary": "12k-25k/æœˆ",
        "companies": "å›½å®¶ç”µç½‘ã€å—æ–¹ç”µç½‘ã€è®¸ç»§ç”µæ°”ã€å›½ç”µå—ç‘",
        "national_strategic": True,
        "strategic_field": "èƒ½æºç”µåŠ›",
    },
    {
        "career": "ä¹¡æ‘æŒ¯å…´ä¿¡æ¯åŒ–å·¥ç¨‹å¸ˆï¼ˆå›½å®¶æˆ˜ç•¥ï¼‰",
        "tags": ["åç«¯", "å‰ç«¯", "æ•°æ®åˆ†æ"],
        "locations": ["å…¨å›½"],
        "skills": ["Web å¼€å‘", "æ•°æ®åº“", "äº‘è®¡ç®—", "ç‰©è”ç½‘"],
        "salary": "10k-20k/æœˆ",
        "companies": "æ”¿åºœä¿¡æ¯åŒ–éƒ¨é—¨ã€å†œä¸šç§‘æŠ€å…¬å¸ã€ç”µå•†å¹³å°",
        "national_strategic": True,
        "strategic_field": "ä¹¡æ‘æŒ¯å…´",
    },
]


def _is_global_location(locations: List[str]) -> bool:
    """Helper function to check if location list is global (empty or contains 'å…¨å›½')."""
    return not locations or locations == [LOCATION_GLOBAL]


def recommend_careers_by_interests_and_location(
    interests: List[str], location: str = "", prioritize_national_strategic: bool = False
) -> List[Dict[str, Any]]:
    """
    æ ¹æ®å…´è¶£æ ‡ç­¾å’Œåœ°åŒºæ¨èèŒä¸šæ–¹å‘ï¼ˆæ”¾å®½æ¡ä»¶ç‰ˆï¼‰.

    - interests: ä¾§è¾¹æ é€‰æ‹©çš„å…´è¶£æ ‡ç­¾åˆ—è¡¨ï¼ˆå³ä½¿åªæœ‰ 1 ä¸ªä¹Ÿä¼šå°½é‡ç»™å‡ºæ¨èï¼‰
    - location: å·¥ä½œåœ°åŒºï¼Œå¦‚ "å…¨å›½" / "åŒ—äº¬" / "ä¸Šæµ·" ç­‰
    - prioritize_national_strategic: æ˜¯å¦ä¼˜å…ˆæ¨èå›½å®¶æˆ˜ç•¥é¢†åŸŸå²—ä½

    è¿”å› List[Dict]ï¼Œæ¯ä¸ªå…ƒç´ ç»“æ„ç±»ä¼¼ï¼š
    {
        "career": "ç®—æ³•å·¥ç¨‹å¸ˆ",
        "skills": [...],
        "salary": "...",
        "companies": "...",
        "score": 3.5,
        "match_reason": "ä¸ä½ çš„å…´è¶£ [æœºå™¨å­¦ä¹ , ç®—æ³•] æœ‰ 2 ä¸ªç›´æ¥åŒ¹é…ï¼›è¯¥èŒä¸šåœ¨ä½ é€‰æ‹©çš„åœ°åŒºï¼ˆåŒ—äº¬ï¼‰æ‹›è˜è¾ƒå¤š"
    }
    """
    interests = [i.strip() for i in (interests or []) if i.strip()]
    location = (location or "").strip() or LOCATION_GLOBAL

    results: List[Dict[str, Any]] = []

    for c in CAREER_CONFIG:
        tags = c.get("tags", []) or []
        locs = c.get("locations", []) or []
        is_national_strategic = c.get("national_strategic", False)

        # åœ°åŒºè¿‡æ»¤ï¼šlocation ä¸º "å…¨å›½" æ—¶ä¸è¿‡æ»¤ï¼›å¦åˆ™åªæœ‰å½“èŒä¸šæ˜ç¡®é™åˆ¶ä¸”ä¸åŒ…å«è¯¥åŸå¸‚æ—¶æ‰æ’é™¤
        if location != LOCATION_GLOBAL:
            if locs and not _is_global_location(locs) and (location not in locs):
                continue

        # å…´è¶£åŒ¹é…ï¼šæŒ‰äº¤é›†ä¸ªæ•°è®¡åˆ†
        if interests:
            overlap = len(set(interests) & set(tags))
        else:
            overlap = 0

        base_score = overlap

        # æ²¡æœ‰å…´è¶£æ ‡ç­¾æ—¶ï¼Œç»™ä¸€ä¸ªåŸºç¡€åˆ†ï¼Œè®©ç³»ç»Ÿä»ç„¶å¯ä»¥æ¨èé€šç”¨å²—ä½
        if not interests:
            base_score = 1
        # æœ‰å…´è¶£ä½†å®Œå…¨æ²¡äº¤é›†ï¼Œå…ˆç»™ 0 åˆ†ï¼Œåé¢çœ‹å…œåº•é€»è¾‘
        elif overlap == 0:
            base_score = 0

        # åœ°åŒºåŠ æˆï¼šå¦‚æœèŒä¸šæœ¬èº«æœ‰åœ°ç‚¹åˆ—è¡¨ä¸”åŒ…å«å½“å‰åœ°ç‚¹ï¼Œå¯ä»¥ +0.5
        loc_bonus = 0.0
        if location != LOCATION_GLOBAL and locs and not _is_global_location(locs) and (location in locs):
            loc_bonus = 0.5

        # å›½å®¶æˆ˜ç•¥é¢†åŸŸåŠ æˆ
        strategic_bonus = 0.0
        if prioritize_national_strategic and is_national_strategic:
            strategic_bonus = NATIONAL_STRATEGIC_BONUS

        score = base_score + loc_bonus + strategic_bonus

        # æœ‰ä¸€ç‚¹åˆ†æ•°å°±å…ˆçº³å…¥å€™é€‰
        if score > 0:
            match_reason_parts = []
            if overlap > 0:
                match_reason_parts.append(
                    f"ä¸ä½ çš„å…´è¶£æ ‡ç­¾ {interests} æœ‰ {overlap} ä¸ªç›´æ¥åŒ¹é…"
                )
            else:
                match_reason_parts.append("ä¸å¸¸è§å¼€å‘/æ•°æ®å²—ä½ç›¸å…³ï¼Œé€‚åˆä½œä¸ºé€šç”¨æ–¹å‘")

            if location != LOCATION_GLOBAL:
                if locs and not _is_global_location(locs) and location in locs:
                    match_reason_parts.append(f"è¯¥èŒä¸šåœ¨ä½ é€‰æ‹©çš„åœ°åŒºï¼ˆ{location}ï¼‰æ‹›è˜è¾ƒå¤š")
                elif _is_global_location(locs):
                    match_reason_parts.append("è¯¥èŒä¸šå¯¹åœ°åŒºè¦æ±‚ä¸é«˜ï¼Œå…¨å›½å¤§éƒ¨åˆ†åŸå¸‚éƒ½æœ‰æœºä¼š")
            else:
                match_reason_parts.append("ä½ é€‰æ‹©äº†ã€å…¨å›½ã€ï¼Œè¯¥èŒä¸šåœ¨å¤šåœ°éƒ½æœ‰éœ€æ±‚")
            
            if is_national_strategic:
                strategic_field = c.get("strategic_field", "å›½å®¶é‡ç‚¹é¢†åŸŸ")
                match_reason_parts.append(f"ğŸ‡¨ğŸ‡³ å›½å®¶æˆ˜ç•¥é‡ç‚¹é¢†åŸŸï¼š{strategic_field}")

            results.append(
                {
                    "career": c.get("career"),
                    "skills": c.get("skills", []),
                    "salary": c.get("salary", ""),
                    "companies": c.get("companies", ""),
                    "score": score,
                    "match_reason": "ï¼›".join(match_reason_parts),
                    "national_strategic": is_national_strategic,
                    "strategic_field": c.get("strategic_field", ""),
                }
            )

    # å¦‚æœä¸¥æ ¼åŒ¹é…ä¸ºç©ºï¼Œä½†ç”¨æˆ·æœ‰å…´è¶£æ ‡ç­¾ï¼Œåˆ™èµ°å…œåº•é€»è¾‘
    if not results and interests:
        backup: List[Dict[str, Any]] = []

        for c in CAREER_CONFIG:
            tags = c.get("tags", []) or []
            if "æœºå™¨å­¦ä¹ " in interests or "ç®—æ³•" in interests:
                if ("æœºå™¨å­¦ä¹ " in tags) or ("ç®—æ³•" in tags) or ("æ•°æ®åˆ†æ" in tags):
                    backup.append(c)
            else:
                # å…¶ä»–å…´è¶£æ—¶ï¼Œç»™ä¸€ä¸¤ä¸ªé€šç”¨å¼€å‘å²—ä½å…œåº•
                if c.get("career") in ("åç«¯å·¥ç¨‹å¸ˆ", "å‰ç«¯å·¥ç¨‹å¸ˆ"):
                    backup.append(c)

        # å¦‚æœ backup è¿˜æ˜¯ç©ºï¼Œå°±ç›´æ¥æŠŠæ‰€æœ‰èŒä¸šå½“å…œåº•å€™é€‰
        if not backup:
            backup = CAREER_CONFIG

        for c in backup:
            results.append(
                {
                    "career": c.get("career"),
                    "skills": c.get("skills", []),
                    "salary": c.get("salary", ""),
                    "companies": c.get("companies", ""),
                    "score": 0.5,
                    "match_reason": "æœªæ‰¾åˆ°ä¸ä½ å…´è¶£é«˜åº¦åŒ¹é…çš„èŒä¸šï¼Œæ¨èä¸€äº›ç›¸å…³æˆ–é€šç”¨çš„è½¯ä»¶/æ•°æ®å²—ä½ä½œä¸ºå…œåº•æ–¹å‘",
                }
            )

    # å»é‡ï¼šåŒå career åªä¿ç•™å¾—åˆ†æœ€é«˜çš„ä¸€æ¡
    if results:
        best_by_name: Dict[str, Dict[str, Any]] = {}
        for r in results:
            name = r.get("career")
            if name not in best_by_name or r.get("score", 0) > best_by_name[name].get(
                "score", 0
            ):
                best_by_name[name] = r
        results = list(best_by_name.values())

        # æœ€åæŒ‰ score é™åºæ’åˆ—ï¼Œæˆªæ–­å‰ 6 ä¸ªï¼Œå’Œä½ åŸæ¥çš„è¡Œä¸ºä¸€è‡´
        results.sort(key=lambda x: x.get("score", 0), reverse=True)
        results = results[:6]

    return results


def generate_learning_path_for_career(
    career: str, interests: List[str], current_level: str = "åˆçº§", agent: AIAgent = None
) -> str:
    agent = agent or st.session_state.get("_global_ai_agent", AIAgent())
    prompt = f"""è¯·ä¸ºä¸€ä¸ª{current_level}æ°´å¹³çš„å­¦ç”Ÿï¼Œé’ˆå¯¹èŒä½'{career}'å’Œå…´è¶£'{', '.join(interests)}'ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„3-6ä¸ªæœˆå­¦ä¹ è·¯å¾„ã€‚

è¦æ±‚ï¼š
1. åˆ†é˜¶æ®µï¼ˆåŸºç¡€ã€è¿›é˜¶ã€é¡¹ç›®å®è·µï¼‰
2. æ¯é˜¶æ®µå…·ä½“å­¦ä¹ å†…å®¹å’Œæ—¶é—´å®‰æ’
3. æ¨èçš„å­¦ä¹ èµ„æºå’Œå¼€æºé¡¹ç›®
4. å®é™…é¡¹ç›®å»ºè®®ï¼ˆ2-3ä¸ªå…·ä½“å°é¡¹ç›®ï¼‰
5. é¢„æœŸè¾¾åˆ°çš„èƒ½åŠ›ç›®æ ‡
6. é¢è¯•å‡†å¤‡å»ºè®®

è¯·ç”¨Markdownæ ¼å¼ç»„ç»‡ç­”æ¡ˆï¼ŒåŠ›æ±‚æ¸…æ™°æ˜“æ‡‚ã€‚"""
    return agent.call(prompt, temperature=0.3, max_tokens=2400)


def recommend_projects_by_agent(
    interests: List[str], skills: List[str], target_career: str
) -> List[Dict[str, Any]]:
    agent: AIAgent = st.session_state.get("_global_ai_agent", AIAgent())

    prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæ¨è5-8ä¸ªé€‚åˆå­¦ä¹ å’Œå®è·µçš„å¼€æºé¡¹ç›®ï¼š

å…´è¶£æ ‡ç­¾ï¼š{', '.join(interests)}
å·²æŒæ¡æŠ€èƒ½ï¼š{', '.join(skills) if skills else 'åˆçº§å¼€å‘è€…'}
ç›®æ ‡èŒä¸šï¼š{target_career or 'æš‚æœªå®š'}

è¦æ±‚ï¼š
1. æ¯ä¸ªé¡¹ç›®åŒ…æ‹¬ï¼šé¡¹ç›®åç§°ã€GitHubé“¾æ¥ã€ç®€çŸ­æè¿°ã€å­¦ä¹ ä»·å€¼ã€éš¾åº¦ç­‰çº§ã€é¢„æœŸå­¦ä¹ æ—¶é—´
2. é¡¹ç›®åº”è¯¥èƒ½å¸®åŠ©è·å¾—ç›®æ ‡èŒä¸šç›¸å…³çš„æŠ€èƒ½
3. é¡¹ç›®éš¾åº¦åº”è¯¥å¾ªåºæ¸è¿›
4. ä¼˜å…ˆæ¨èå¯¹åˆä¸­çº§å¼€å‘è€…å‹å¥½çš„é¡¹ç›®

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆJSONæ ¼å¼ï¼‰ï¼š
```json
[
  {{
    "name": "é¡¹ç›®åç§°",
    "url": "GitHubé“¾æ¥",
    "description": "ç®€çŸ­æè¿°",
    "learning_value": "å­¦ä¹ ä»·å€¼",
    "difficulty": "easy/medium/hard",
    "estimated_time": "é¢„æœŸå­¦ä¹ æ—¶é—´ï¼ˆå‘¨ï¼‰",
    "tech_stack": ["æŠ€æœ¯æ ˆ"]
  }}
]åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
    result_text = agent.call(prompt, temperature=0.3, max_tokens=3000)

    try:
        import re

        json_match = re.search(r"```json\n(.*?)\n```", result_text, re.DOTALL)
        json_str = json_match.group(1) if json_match else result_text.strip()
        projects = json.loads(json_str)
        if isinstance(projects, list):
            return projects
    except Exception as e:
        logger.warning(f"Failed to parse agent projects recommendation: {e}")

    return [
        {
            "name": "Vue 3",
            "url": "https://github.com/vuejs/core",
            "description": "å­¦ä¹ ç°ä»£å‰ç«¯æ¡†æ¶",
            "learning_value": "å‰ç«¯å·¥ç¨‹å®æˆ˜",
            "difficulty": "medium",
            "estimated_time": "8",
            "tech_stack": ["JavaScript", "Vue"],
        },
        {
            "name": "FastAPI",
            "url": "https://github.com/tiangolo/fastapi",
            "description": "é«˜æ€§èƒ½ Python Web æ¡†æ¶",
            "learning_value": "åç«¯å¼€å‘å®æˆ˜",
            "difficulty": "medium",
            "estimated_time": "6",
            "tech_stack": ["Python", "FastAPI"],
        },
    ]

def explain_course_recommendation(course: Dict[str, Any], user_interests: List[str], score: float) -> str:
    """
    Generate an explanation for why a course is recommended.
    
    Args:
        course: Course dictionary
        user_interests: List of user's interests
        score: Recommendation score
        
    Returns:
        Human-readable explanation string
    """
    explanations = []
    
    course_name = course.get("name", "è¯¥è¯¾ç¨‹")
    
    # Interest matching
    matched_interests = []
    for interest in user_interests:
        if interest.lower() in course_name.lower() or interest.lower() in course.get("outline", "").lower():
            matched_interests.append(interest)
    
    if matched_interests:
        explanations.append(f"ä¸æ‚¨çš„å…´è¶£ã€{', '.join(matched_interests)}ã€‘é«˜åº¦åŒ¹é…")
    
    # Level appropriateness
    level = course.get("level", "")
    if level:
        level_desc = {
            "æœ¬ç§‘": "é€‚åˆæœ¬ç§‘é˜¶æ®µå­¦ä¹ ",
            "ç ”ç©¶ç”Ÿ": "ç ”ç©¶ç”Ÿæ·±åº¦è¯¾ç¨‹",
            "ä»·å€¼å¼•é¢†ç±»": "æ€æ”¿ä»·å€¼å¼•é¢†è¯¾ç¨‹"
        }.get(level, f"{level}è¯¾ç¨‹")
        explanations.append(level_desc)
    
    # Ideological value
    if course.get("ideological"):
        explanations.append("ğŸ’ ä»·å€¼å¼•é¢†è¯¾ç¨‹ï¼ŒåŸ¹å…»æŠ€æœ¯ä¼¦ç†")
    
    # Score-based description
    if score > 80:
        explanations.append("ğŸŒŸ å¼ºçƒˆæ¨è")
    elif score > 50:
        explanations.append("ğŸ‘ æ¨èå­¦ä¹ ")
    
    if not explanations:
        return "æ ¹æ®æ‚¨çš„å­¦ä¹ è§„åˆ’æ¨è"
    
    return "ï¼›".join(explanations)


def explain_advisor_recommendation(advisor: Dict[str, Any], user_interests: List[str]) -> str:
    """
    Generate an explanation for why an advisor is recommended.
    
    Args:
        advisor: Advisor dictionary
        user_interests: List of user's interests
        
    Returns:
        Human-readable explanation string
    """
    explanations = []
    
    # Research area matching
    research = advisor.get("research", "")
    matched_interests = []
    for interest in user_interests:
        if interest.lower() in research.lower():
            matched_interests.append(interest)
    
    if matched_interests:
        explanations.append(f"ç ”ç©¶æ–¹å‘ä¸ã€{', '.join(matched_interests)}ã€‘ç›¸å…³")
    
    # National projects
    if advisor.get("national_projects"):
        explanations.append("ğŸ‡¨ğŸ‡³ å‚ä¸å›½å®¶é‡å¤§é¡¹ç›®")
    
    # Department
    dept = advisor.get("department", "")
    if dept:
        explanations.append(f"{dept}")
    
    if not explanations:
        return "ä¼˜ç§€å¯¼å¸ˆæ¨è"
    
    return "ï¼›".join(explanations)


def explain_practice_recommendation(practice: Dict[str, Any], user_interests: List[str], social_score: float = 0) -> str:
    """
    Generate an explanation for why a practice resource is recommended.
    
    Args:
        practice: Practice resource dictionary
        user_interests: List of user's interests
        social_score: Social value score
        
    Returns:
        Human-readable explanation string
    """
    explanations = []
    
    # Interest matching
    practice_name = practice.get("name", "")
    practice_desc = practice.get("description", "")
    matched_interests = []
    for interest in user_interests:
        if interest.lower() in practice_name.lower() or interest.lower() in practice_desc.lower():
            matched_interests.append(interest)
    
    if matched_interests:
        explanations.append(f"ä¸ã€{', '.join(matched_interests)}ã€‘ç›¸å…³")
    
    # Social value
    if social_score > 0:
        explanations.append("ğŸ’ å…·æœ‰ç¤¾ä¼šä»·å€¼æˆ–æœåŠ¡å›½å®¶æˆ˜ç•¥")
    
    # Type
    ptype = practice.get("type", "")
    if ptype:
        explanations.append(f"{ptype}ç±»èµ„æº")
    
    if not explanations:
        return "å®è·µèµ„æºæ¨è"
    
    return "ï¼›".join(explanations)


def explain_career_recommendation(career: Dict[str, Any], user_interests: List[str], location: str, is_strategic: bool = False) -> str:
    """
    Generate an explanation for why a career is recommended.
    
    Args:
        career: Career dictionary
        user_interests: List of user's interests
        location: User's preferred location
        is_strategic: Whether it's a national strategic position
        
    Returns:
        Human-readable explanation string
    """
    explanations = []
    
    # Interest matching
    career_name = career.get("name", "")
    matched_interests = []
    for interest in user_interests:
        if interest.lower() in career_name.lower():
            matched_interests.append(interest)
    
    if matched_interests:
        explanations.append(f"åŒ¹é…æŠ€èƒ½ã€{', '.join(matched_interests)}ã€‘")
    
    # Strategic position
    if is_strategic:
        explanations.append("ï¿½ï¿½ğŸ‡³ å›½å®¶æˆ˜ç•¥é‡ç‚¹å²—ä½")
    
    # Location
    career_location = career.get("location", "")
    if career_location and location and location != "å…¨å›½":
        if location in career_location:
            explanations.append(f"ğŸ“ ç¬¦åˆæœŸæœ›åœ°åŒºã€{location}ã€‘")
    
    # Demand
    demand = career.get("demand", "")
    if demand == "é«˜":
        explanations.append("ğŸ”¥ å¸‚åœºéœ€æ±‚æ—ºç››")
    
    if not explanations:
        return "èŒä¸šå‘å±•æ¨è"
    
    return "ï¼›".join(explanations)
